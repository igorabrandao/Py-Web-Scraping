{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Project - Unit 3,2\n",
    "*by Igor A. Brandão and Leandro Antonio Feliciano da Silva*\n",
    "\n",
    "**Goals**\n",
    "The purpose of this project is explore the following:\n",
    "\n",
    "- Access a content using webscraping way;\n",
    "- Catch the following data about people:\n",
    "\n",
    "\n",
    "1. About\n",
    "2. RG\n",
    "3. CPF\n",
    "4. CNPJ\n",
    "5. Name\n",
    "6. Marital state\n",
    "7. Birthdate\n",
    "8. Age\n",
    "9. Education level\n",
    "10. Language\n",
    "11. Workplace\n",
    "12. Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports section\n",
    "\n",
    "#### Import the necessary libraries to handle \n",
    "\n",
    "- Requests;\n",
    "- urlopen;\n",
    "- HTTPError;\n",
    "- BeautifulSoup\n",
    "- Regular expression\n",
    "- Tqdm progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/igorbrandao/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: tabulate in /home/igorbrandao/anaconda3/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "### Library necessary to run this IPython Notebook\n",
    "!pip install tqdm\n",
    "\n",
    "### Library necessary to tabulate python outputs\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables section\n",
    "\n",
    "#### This section contains is used to define the content variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Content variables\n",
    "about_me = \"\"\n",
    "rg = \"\"\n",
    "cpf = \"\"\n",
    "cnpj = \"\"\n",
    "name = \"\"\n",
    "marital_state = \"\"\n",
    "birthdate = \"\"\n",
    "age = \"\"\n",
    "education_level = []\n",
    "language = []\n",
    "workplace = []\n",
    "salary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function section\n",
    "\n",
    "#### This section contains all the generic functions used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return an soup Object\n",
    "def getSoup(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the dirty part from link\n",
    "def getLink(url, dirty):\n",
    "    result = url.split(dirty)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input section\n",
    "\n",
    "#### This section cover all the basic parameters used to perform the web scrapping operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Global parameters]\n",
    "\n",
    "# Search term (person name)\n",
    "search_term = \"Ivanovitch Medeiros Dantas da Silva\"\n",
    "\n",
    "# Search limiter\n",
    "search_results_number = \"20\"\n",
    "\n",
    "# Number of recursion (how many levels the search will dig)\n",
    "recursion_number = 2\n",
    "\n",
    "# Base URI\n",
    "search_url = \"https://www.google.com.br/search?q=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we assemble the final search URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First of all, replace blank spaces by add signals to perform the search\n",
    "search_term_adapted = re.sub(\" \", \"+\", search_term)\n",
    "\n",
    "# Assembly the search URI\n",
    "url = (search_url + search_term_adapted + \"&num=\" + search_results_number)\n",
    "\n",
    "# Access the page content\n",
    "soup = getSoup(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing section\n",
    "\n",
    "#### This section is responsible for handle the processing\n",
    "\n",
    "#### *Warning:* The *url* must be properly assembled for this section work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Processing parameters]\n",
    "\n",
    "# Search method\n",
    "# It's define how we'll look for the results section\n",
    "# Possible methods {id, tag, className}\n",
    "search_method = \"id\"\n",
    "\n",
    "# Result tag ID (the idea here is just getting the search result and ignore what's left over)\n",
    "result_tag_id = \"res\"\n",
    "\n",
    "# HTML container element\n",
    "element = \"div\"\n",
    "\n",
    "# Class name\n",
    "class_name = \"\"\n",
    "\n",
    "# Content variable\n",
    "content = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the choosen search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the search method\n",
    "if search_method == \"id\":\n",
    "   content = soup.findAll(element, id=result_tag_id)[0]\n",
    "elif search_method == \"tag\":\n",
    "   content = soup.findAll(element, limit=1)\n",
    "elif search_method == \"className\":\n",
    "   content = soup.find(class_=class_name)\n",
    "else:\n",
    "   print(\"You must choose one search method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of result links and put into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 19155.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Link list\n",
    "link_list = []\n",
    "link_list_content = []\n",
    "link = \"\"\n",
    "\n",
    "# Filter (to avoid receiving undesirable URIs)\n",
    "filters = ['webcache', '.pdf', '.doc', '.docx', '.xls', '.xlsx', 'facebook', 'sigaa']\n",
    "\n",
    "# Add the links to the list\n",
    "for item in tqdm(content.find_all('a')):\n",
    "    \n",
    "    # Check if exist a href attribute\n",
    "    if 'href' in item.attrs:\n",
    "        \n",
    "        # Check if it's a link\n",
    "        if 'http' in str(item.attrs):\n",
    "            \n",
    "            # Filter the results accordling to the filter list\n",
    "            if not any(filter_item in str(item.attrs) for filter_item in filters):\n",
    "                \n",
    "                # Remove the dirty part from the link using the defined function getLink()\n",
    "                link = getLink(item.attrs['href'].replace(\"/url?q=\", \"\"), \"&sa=\")\n",
    "                link_list.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run into inside links n levels (depends on recursion_number)\n",
    "\n",
    "**Important:** recursion_number = 2 means read the search page and its sub-links (1 level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f66b478cac8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the links to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlink_list_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===============================================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2f3cb70c9f7e>\u001b[0m in \u001b[0;36mgetSoup\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    486\u001b[0m         }\n\u001b[1;32m    487\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    421\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                 )\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    592\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 138\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igorbrandao/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Add the links to the list\n",
    "for idx, item in tqdm(enumerate(link_list)):\n",
    "    link_list_content.append(getSoup(item))\n",
    "    print(item)\n",
    "    print(\"===============================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page scrapping function section\n",
    "\n",
    "#### This section contains the functions to dig the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an soup Object\n",
    "def getFromEscavador(content_, contentType_):\n",
    "    \n",
    "    # ==========================================================\n",
    "    # About\n",
    "    # ==========================================================\n",
    "    if contentType_ == \"about\":\n",
    "        \n",
    "        # Dig the elements\n",
    "        first_div = content_.find('div',{\"class\" : \"box -flushHorizontal\"})\n",
    "        child_element = first_div.findAll('p', limit=1)\n",
    "        \n",
    "        # Assign the result\n",
    "        return(child_element[0].text)\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Name\n",
    "    # ==========================================================\n",
    "    elif contentType_ == \"name\":\n",
    "        \n",
    "        # Dig the elements and return the result\n",
    "        return(content_.find(class_=\"heading name\").text)\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Education level\n",
    "    # ==========================================================\n",
    "    elif contentType_ == \"education_level\":\n",
    "        \n",
    "        # Array with education\n",
    "        education = []\n",
    "        \n",
    "        # Dig the elements\n",
    "        for item in content_.findAll(class_='heading -likeH5 inline-edit-item inline-edit-item-formacao'):\n",
    "            if item.text:\n",
    "                education.append(item.text)\n",
    "        \n",
    "        # Return the education list\n",
    "        return(education)\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Language\n",
    "    # ==========================================================\n",
    "    elif contentType_ == \"language\":\n",
    "        \n",
    "        # Array with languages\n",
    "        language_list = []\n",
    "        \n",
    "        # Dig the elements\n",
    "        for item in content_.findAll('div', id='idiomas'):\n",
    "            if item:\n",
    "                # Look for all languages\n",
    "                for subitem in item.findAll(class_='col-sm-6 clearfix-box'):\n",
    "                    # Get the language description\n",
    "                    child_element = subitem.findAll('p', limit=2)\n",
    "\n",
    "                    if child_element[0] and child_element[1]:\n",
    "                        # Append it to the language list\n",
    "                        language_list.append(child_element[0].text + \" - \" + child_element[1].text.replace('\\n', ' '))\n",
    "        \n",
    "        # Return the education list\n",
    "        return(language_list)\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Workplace\n",
    "    # ==========================================================\n",
    "    elif contentType_ == \"workplace\":\n",
    "        \n",
    "        # Array with workplaces\n",
    "        workplace_list = []\n",
    "        \n",
    "        # Dig the elements\n",
    "        for item in content_.findAll('div', id='endereco-profissional'):\n",
    "            if item:\n",
    "                # Look for all workplaces\n",
    "                for subitem in item.findAll(class_='item'):\n",
    "                    # Get the workplace description\n",
    "                    child_element = subitem.find('p')\n",
    "\n",
    "                    if child_element:\n",
    "                        # Append it to the language list\n",
    "                        workplace_list.append(child_element.text)\n",
    "        \n",
    "        # Return the education list\n",
    "        return(workplace_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return an soup Object\n",
    "# Important: This function works just with public workers\n",
    "def getFromPortalDaTransparencia(contentType_):\n",
    "    \n",
    "    if contentType_ == \"salary\":\n",
    "    \n",
    "        # ==========================================================\n",
    "        # Public worker ID and CPF\n",
    "        # ==========================================================\n",
    "    \n",
    "        # Handle global search term\n",
    "        global search_term\n",
    "        \n",
    "        # Worker informations handler\n",
    "        worker_id = 0;\n",
    "        worker_info = []\n",
    "        \n",
    "        # Base URI\n",
    "        search_url = \"http://www.portaltransparencia.gov.br/servidores/Servidor-ListaServidores.asp?bogus=1&Pagina=1&TextoPesquisa=\"\n",
    "        \n",
    "        # First of all, replace blank spaces by add signals to perform the search\n",
    "        search_term_adapted = re.sub(\" \", \"%20\", search_term)\n",
    "\n",
    "        # Assembly the search URI\n",
    "        url = (search_url + search_term_adapted)\n",
    "\n",
    "        # Access the page content\n",
    "        salary_content = getSoup(url)\n",
    "        \n",
    "        # Dig the elements\n",
    "        for item in salary_content.findAll('div', id='listagem'):\n",
    "            if item:\n",
    "\n",
    "                 # Check if exist a href attribute\n",
    "                for subitem in item.findAll('td'):\n",
    "                    \n",
    "                    # Get the worker CPF\n",
    "                    if 'class' in subitem.attrs:\n",
    "                        worker_info.append(subitem.text)\n",
    "    \n",
    "                    # Get the worker id\n",
    "                    for sub_subitem in subitem.findAll('a'):\n",
    "                    \n",
    "                        if 'href' in sub_subitem.attrs:\n",
    "                \n",
    "                            # Check if it's a link\n",
    "                            if 'IdServidor' in str(sub_subitem.attrs):\n",
    "\n",
    "                                # Remove the dirty part from the link\n",
    "                                result = sub_subitem.attrs['href'].split('IdServidor=')\n",
    "                                workerId = result[1]\n",
    "                        \n",
    "                                # Get the worker id\n",
    "                                worker_info.append(worker_id)\n",
    "                                worker_id = workerId\n",
    "                    \n",
    "        # ==========================================================\n",
    "        # Public worker salary\n",
    "        # ==========================================================\n",
    "        \n",
    "        # Check if worker informations was found\n",
    "        if worker_info:\n",
    "            \n",
    "            # Renew worker_info array\n",
    "            worker_info = []\n",
    "            worker_info.append(worker_id)\n",
    "            \n",
    "            # Base URI\n",
    "            search_url = \"http://www.portaltransparencia.gov.br/servidores/Servidor-DetalhaRemuneracao.asp?Op=1&IdServidor=\" + worker_id + \"&bInformacaoFinanceira=True\"\n",
    "\n",
    "            # Access the page content\n",
    "            salary_detail_content = getSoup(search_url)\n",
    "            \n",
    "            # Dig the elements\n",
    "            for item in salary_detail_content.findAll('td',{\"class\" : \"colunaValor\"}):\n",
    "                \n",
    "                if item.text.strip():\n",
    "                    worker_info.append(item.text.strip())\n",
    "        \n",
    "        return(worker_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the information (it is the main flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, run through link list content\n",
    "for idx, item in tqdm(enumerate(link_list_content)):\n",
    "    \n",
    "    # Try to look for the information in available sources\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Escavador source\n",
    "    # ==========================================================\n",
    "    if \"Escavador\" in str(item) or \"escavador\" in str(item):\n",
    "        \n",
    "        # Get informations from Escavador\n",
    "        if not name:\n",
    "            name = getFromEscavador(item, \"name\")\n",
    "            \n",
    "        if not about_me:\n",
    "            about_me = getFromEscavador(item, \"about\")\n",
    "            \n",
    "        if not education_level:\n",
    "            education_level = getFromEscavador(item, \"education_level\")\n",
    "            \n",
    "        if not language:\n",
    "            language = getFromEscavador(item, \"language\")\n",
    "            \n",
    "        if not workplace:\n",
    "            workplace = getFromEscavador(item, \"workplace\")\n",
    "    \n",
    "    # ==========================================================\n",
    "    # Other source\n",
    "    # =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the salary (just work with public workers)\n",
    "salary = getFromPortalDaTransparencia(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result section\n",
    "\n",
    "#### Now it's the time of truth, let's see whats our program can bring about you ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to output the result as a Markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Imports to tabulate outputs\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ==========================================================\n",
    "# Display informations\n",
    "# ==========================================================\n",
    "display(Markdown('# Hello, ' + name + '!'))\n",
    "display(Markdown('<hr>'))\n",
    "\n",
    "# Name\n",
    "if name:\n",
    "    display(Markdown('**Your name:** ' + name))\n",
    "\n",
    "# About you\n",
    "if about_me:\n",
    "    display(Markdown('**Some about you:** ' + about_me))\n",
    "\n",
    "# Education level (print as a tabular list)\n",
    "if education_level:\n",
    "    display(Markdown('**Education level:**'))\n",
    "    \n",
    "    list = zip(education_level)\n",
    "    print(tabulate(list))\n",
    "\n",
    "# Languages (print as a tabular list)\n",
    "if language:\n",
    "    display(Markdown('**Language(s):**'))\n",
    "    \n",
    "    list = zip(language)\n",
    "    print(tabulate(list))\n",
    "    \n",
    "# Workplaces (print as a tabular list)\n",
    "if workplace:\n",
    "    display(Markdown('**Workplace(s):**'))\n",
    "    \n",
    "    list = zip(workplace)\n",
    "    print(tabulate(list))\n",
    "\n",
    "# Salary\n",
    "if salary:\n",
    "    display(Markdown('**Salary informations:**'))\n",
    "    \n",
    "    display(Markdown('*Worker ID: *' + salary[0]))\n",
    "    display(Markdown('*Worker CPF: *' + salary[2]))\n",
    "    display(Markdown('*Worker Type: *' + salary[3]))\n",
    "    display(Markdown('<hr>'))\n",
    "    display(Markdown('***Base salary: *' + 'R$ ' + salary[4]))\n",
    "    display(Markdown('*IRRF: *' + 'R$ ' + salary[5]))\n",
    "    display(Markdown('*PSS/RPGS: *' + 'R$ ' + salary[6]))\n",
    "    display(Markdown('*Other discounts: *' + 'R$ ' + salary[7]))\n",
    "    display(Markdown('*Final salary: *' + 'R$ ' + salary[8]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
